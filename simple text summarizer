import nltk 
import string
from heapq import nlargest

nltk.download('stopwords')
nltk.download('punkt')

text = input("Paste text that you want to summarize: ")
percent = int(input("Paste percent of text that you want to see as summary: "))

if percent <= 0:
    raise ValueError("Percent must be greater than 0")
if text.count(". ") == 0:
    raise ValueError("Text must contain at least one sentence ending with '. '")

length = max(1, int(round(text.count(". ") / percent, 0)))

nopunc = [char for char in text if char not in string.punctuation]
nopunc = "".join(nopunc)

processed_text = [
    word for word in nopunc.split() 
    if word.lower() not in nltk.corpus.stopwords.words('english')
]

word_freq = {}
for word in processed_text:
    if word not in word_freq:
        word_freq[word] = 1
    else:
        word_freq[word] += 1
        
max_freq = max(word_freq.values())
for word in word_freq.keys():
    word_freq[word] = (word_freq[word] / max_freq)
    
sent_list = nltk.sent_tokenize(text)

sent_score = {}
for sent in sent_list:
    for word in nltk.word_tokenize(sent.lower()):
        if word in word_freq.keys():
            if sent not in sent_score.keys():
                sent_score[sent] = word_freq[word]
            else:
                sent_score[sent] += word_freq[word]

summary_sents = nlargest(length, sent_score, key=sent_score.get)

summary = " ".join(summary_sents)
print(summary)
